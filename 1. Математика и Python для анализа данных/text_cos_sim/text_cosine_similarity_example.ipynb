{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная алгебра: сходство текстов и аппроксимация функций\n",
    "\n",
    "Данное задание основано на материалах секции, посвященной введению в линейную алгебру. Вам понадобится компьютер с установленным интерпретатором Python и подключенными библиотеками NumPy и SciPy.\n",
    "\n",
    "### Вы научитесь:\n",
    "  * читать тексты из файла с помощью Python и разбивать их на слова\n",
    "  * переводить тексты в векторные пространства, вычислять расстояния в этих пространствах\n",
    "  * решать системы линейных уравнений\n",
    "  * приближать любые функции с помощью многочленов\n",
    "  \n",
    "## Введение\n",
    "\n",
    "В этом задании вы познакомитесь с некоторыми базовыми методами из линейной алгебры, реализованными в пакете SciPy — в частности, с методами подсчета косинусного расстояния и решения систем линейных уравнений. Обе эти задачи еще много раз встретятся нам в специализации. Так, на решении систем линейных уравнений основана настройка линейных моделей — очень большого и важного класса алгоритмов машинного обучения. Косинусное расстояние же часто используется в анализе текстов для измерения сходства между ними.\n",
    "\n",
    "## Материалы\n",
    "\n",
    "Справка по функциям пакета scipy.linalg: http://docs.scipy.org/doc/scipy/reference/linalg.html\n",
    "\n",
    "Справка по работе с файлами в Python: https://docs.python.org/2/tutorial/inputoutput.html#reading-and-writing-files\n",
    "\n",
    "Справка по регулярным выражениям в Python (если вы захотите узнать про них чуть больше): https://docs.python.org/2/library/re.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача: сравнение предложений\n",
    "\n",
    "Дан набор предложений, скопированных с Википедии. Каждое из них имеет \"кошачью тему\" в одном из трех смыслов:\n",
    "\n",
    "  * кошки (животные)\n",
    "  * UNIX-утилита cat для вывода содержимого файлов\n",
    "  * версии операционной системы OS X, названные в честь семейства кошачьих\n",
    "Ваша задача — найти два предложения, которые ближе всего по смыслу к расположенному в самой первой строке. В качестве меры близости по смыслу мы будем использовать косинусное расстояние.\n",
    "\n",
    "#### Выполните следующие шаги:\n",
    "\n",
    "1. Скачайте файл с предложениями (sentences.txt).\n",
    "2. Каждая строка в файле соответствует одному предложению. Считайте их, приведите каждую к нижнему регистру с помощью строковой функции lower().\n",
    "3. Произведите токенизацию, то есть разбиение текстов на слова. Для этого можно воспользоваться регулярным выражением, которое считает разделителем любой символ, не являющийся буквой: re.split('[^a-z]', t). Не забудьте удалить пустые слова после разделения.\n",
    "4. Составьте список всех слов, встречающихся в предложениях. Сопоставьте каждому слову индекс от нуля до (d - 1), где d — число различных слов в предложениях. Для этого удобно воспользоваться структурой dict.\n",
    "5. Создайте матрицу размера n x d, где n — число предложений. Заполните ее: элемент с индексом (i, j) в этой матрице должен быть равен количеству вхождений j-го слова в i-е предложение. У вас должна получиться матрица размера 22 * 254.\n",
    "6. Найдите косинусное расстояние от предложения в самой первой строке (In comparison to dogs, cats have not undergone...) до всех остальных с помощью функции scipy.spatial.distance.cosine. Какие номера у двух предложений, ближайших к нему по этому расстоянию (строки нумеруются с нуля)? Эти два числа и будут ответами на задание.\n",
    "7. Запишите полученные числа в файл, разделив пробелом. Обратите внимание, что файл должен состоять из одной строки, в конце которой не должно быть переноса. Пример файла с решением вы можете найти в конце задания (submission-1.txt).\n",
    "8. Совпадают ли ближайшие два предложения по тематике с первым? Совпадают ли тематики у следующих по близости предложений?\n",
    "\n",
    "Разумеется, использованный вами метод крайне простой. Например, он не учитывает формы слов (так, cat и cats он считает разными словами, хотя по сути они означают одно и то же), не удаляет из текстов артикли и прочие ненужные слова. Позже мы будем подробно изучать анализ текстов, где выясним, как достичь высокого качества в задаче поиска похожих предложений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считывание строк из файла\n",
    "with open('sentences.txt', 'r') as f:\n",
    "    sentences = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in comparison to dogs, cats have not undergone major changes during the domestication process.\\n',\n",
       " 'as cat simply catenates streams of bytes, it can be also used to concatenate binary files, where it will just concatenate sequence of bytes.\\n',\n",
       " 'a common interactive use of cat for a single file is to output the content of a file to standard output.\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Приведение к нижнему регистру\n",
    "sentences = [sentence.lower() for sentence in sentences]\n",
    "sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in',\n",
       " 'comparison',\n",
       " 'to',\n",
       " 'dogs',\n",
       " 'cats',\n",
       " 'have',\n",
       " 'not',\n",
       " 'undergone',\n",
       " 'major',\n",
       " 'changes',\n",
       " 'during',\n",
       " 'the',\n",
       " 'domestication',\n",
       " 'process']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Токенизация: разбиение на слова с помощью регулярного выражения\n",
    "tokenized_sentences = [re.split('[^a-z]', sentence) for sentence in sentences]\n",
    "\n",
    "# Удаление пустых слов\n",
    "tokenized_sentences = [[word for word in sentence if word] for sentence in tokenized_sentences]\n",
    "\n",
    "tokenized_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список всех уникальных слов\n",
    "all_words = set(word for sentence in tokenized_sentences for word in sentence)\n",
    "\n",
    "# Сопоставляем каждому слову индекс\n",
    "word_to_index = {word: idx for idx, word in enumerate(all_words)}\n",
    "# word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Размеры матрицы\n",
    "n = len(tokenized_sentences)\n",
    "d = len(word_to_index)\n",
    "\n",
    "# Создаем пустую матрицу\n",
    "matrix = np.zeros((n, d))\n",
    "\n",
    "# Заполняем её\n",
    "for i, sentence in enumerate(tokenized_sentences):\n",
    "    for word in sentence:\n",
    "        matrix[i, word_to_index[word]] += 1\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9527544408738466,\n",
       " 0.8644738145642124,\n",
       " 0.8951715163278082,\n",
       " 0.7770887149698589,\n",
       " 0.9402385695332803,\n",
       " 0.7327387580875756,\n",
       " 0.9258750683338899,\n",
       " 0.8842724875284311,\n",
       " 0.9055088817476932,\n",
       " 0.8328165362273942,\n",
       " 0.8804771390665607,\n",
       " 0.8396432548525454,\n",
       " 0.8703592552895671,\n",
       " 0.8740118423302576,\n",
       " 0.9442721787424647,\n",
       " 0.8406361854220809,\n",
       " 0.956644501523794,\n",
       " 0.9442721787424647,\n",
       " 0.8885443574849294,\n",
       " 0.8427572744917122,\n",
       " 0.8250364469440588]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Косинусное расстояние от первого предложения до всех остальных\n",
    "distances = [cosine(matrix[0], matrix[i]) for i in range(1, n)]\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Номера предложений: [6 4]\n"
     ]
    }
   ],
   "source": [
    "# Находим два предложения с наименьшим расстоянием\n",
    "closest_sentences = np.argsort(distances)[:2] + 1  # Добавляем 1, так как индексы сдвинуты\n",
    "print(\"Номера предложений:\", closest_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Записываем результат в файл\n",
    "with open('submission.txt', 'w') as f:\n",
    "    f.write(' '.join(map(str, closest_sentences)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
